# KB Search Output Format Clarification

**Date**: 2025-10-11  
**Status**: ✅ Clarified

## Expected Output Format

When users ask about past conversations, the bot should provide:

1. **LLM Summary** (1-2 sentences) - Brief, conversational summary
2. **Separator Line** - Visual break
3. **Message Snippets** - Formatted cards with links

### Example Output Structure

```
User: "@GuruKeeperBot What did we discuss about deployment?"

Bot Response:
┌─────────────────────────────────────────┐
│ Found several discussions about         │  ← LLM SUMMARY (main LLM)
│ deployment strategies:                  │
├─────────────────────────────────────────┤
│ ━━━━━━━━━━━━━━━━━━━━                    │  ← SEPARATOR
│ 📚 Found 3 relevant message(s):         │  ← TOOL OUTPUT (search_knowledge_base)
│                                         │
│ 1. 👤 Alice • 👥 Group • 2025-10-11    │
│    🔗 View in group                     │
│    💬 "We should deploy using Docker..." │
│                                         │
│ 2. 👤 Bob • 👥 Group • 2025-10-10      │
│    🔗 View in group                     │
│    💬 "Kubernetes would be better..."   │
│                                         │
│ 3. 👤 Carol • 👥 Group • 2025-10-09    │
│    🔗 View in group                     │
│    💬 "Let's discuss deployment at..."  │
│                                         │
│ ━━━━━━━━━━━━━━━━━━━━                    │
└─────────────────────────────────────────┘
```

## How It Works

### 1. LLM Summary (Main LLM - GPT-4)

**Generated by**: The main conversational LLM  
**Purpose**: Provide context and introduce the search results  
**Format**: 1-2 conversational sentences  

**Examples**:
- English: "Found several discussions about X:"
- Russian: "Нашёл несколько обсуждений про X:"

**Instructions to LLM**:
```
Provide a BRIEF 1-2 sentence summary introducing the search results.
Be conversational and natural. Keep it SHORT.
```

### 2. Tool Output (search_knowledge_base)

**Generated by**: The KB search tool  
**Purpose**: Show actual messages with clickable links  
**Format**: Structured message cards  

**Contains**:
- Separator lines (`━━━━━━`)
- Result count header
- Individual message cards:
  - Sender emoji and name (👤 User / 🤖 Bot)
  - Source indicator (👥 Group / 👤 DM)
  - Date/time
  - Clickable deeplink (🔗 View in group)
  - Message preview (truncated to ~150 chars)

## Code Flow

### Step 1: User Asks Question
```
User: "@GuruKeeperBot What did we discuss about X?"
```

### Step 2: Main LLM Decides to Use Tool
```
System Prompt: "You MUST use search_knowledge_base when users ask about past conversations"
LLM: "I need to search the knowledge base for this"
```

### Step 3: LLM Generates Response WITH Tool Call
```python
# LLM's response includes:
- Text part: "Found several discussions about X:"
- Tool call: search_knowledge_base(query="X")
```

### Step 4: Tool Executes and Returns Formatted Snippets
```python
# search_knowledge_base returns:
"""
━━━━━━━━━━━━━━━━━━━━
📚 Found 3 relevant message(s):

1. 👤 User • 👥 Group • Date
   🔗 View in group
   💬 "Message preview..."

━━━━━━━━━━━━━━━━━━━━
"""
```

### Step 5: Streaming Service Combines Output
```python
# llm_service.py combines:
full_response = llm_text + tool_output

# Result:
"Found several discussions about X:

━━━━━━━━━━━━━━━━━━━━
📚 Found 3 relevant message(s):

1. Message card...
━━━━━━━━━━━━━━━━━━━━"
```

### Step 6: Display to User
```python
# group_messages.py checks if KB snippets exist
has_kb_snippets = '━━━━━━━━━━━━━━━━━━━━' in full_response
if has_kb_snippets:
    # Don't escape HTML - preserve clickable links
    formatted_response = full_response
else:
    formatted_response = escape_html(full_response)

await message.reply(formatted_response, parse_mode="HTML")
```

## Important Notes

### What the Tool Does NOT Do

The `search_knowledge_base` tool does **NOT**:
- ❌ Generate AI summaries internally
- ❌ Try to explain what was found
- ❌ Provide context or narrative

It **ONLY** returns:
- ✅ Formatted message cards
- ✅ Clickable deeplinks
- ✅ Structured data

### What the Main LLM Does

The main LLM (GPT-4):
- ✅ Provides conversational context
- ✅ Generates the summary
- ✅ Calls the tool when needed
- ✅ Introduces the results naturally

### Removed Code

Removed unused internal summary generation (`_generate_kb_summary`):
- Was generating summaries but never using them
- Created unnecessary LLM calls
- Main LLM's summary is better and more contextual

## System Prompt Instructions

Clear instructions to the LLM:

```
**How to use search_knowledge_base:**

1. First, provide your BRIEF 1-2 sentence summary
   Example: "Found several discussions about X:"

2. Then call search_knowledge_base(query="X")

3. The tool returns formatted message cards with links

4. Do NOT reformat the results - they're already formatted

5. Your summary appears first, tool output below

**Example flow:**
User: "What did we discuss?"
You: "Found several discussions:" [tool outputs formatted cards below]
```

## Testing

To verify correct format:

1. Ask: `@BotName What did we discuss about X?`

2. Expected response:
   ```
   [1-2 sentence summary]
   
   ━━━━━━━━━━━━━━━━━━━━
   📚 Found N message(s):
   
   1. Message card...
   2. Message card...
   
   ━━━━━━━━━━━━━━━━━━━━
   ```

3. Verify:
   - ✅ Summary is brief and natural
   - ✅ Links are clickable (not plain text)
   - ✅ Only original messages shown (no bot summaries)
   - ✅ Consistent formatting

## Files Modified

1. `/Users/evgenyvakhteev/Documents/src/dexguru/bot/luka_bot/agents/tools/knowledge_base_tools.py`
   - Removed unused `_generate_kb_summary` code reference
   - Clarified comments about tool responsibility
   - Enhanced system prompt with example flow

## Related Documentation

- `KB_SEARCH_FINAL_FIXES.md` - HTML links & bot filtering
- `KB_TOOL_EMPHASIS_UPDATE.md` - Tool usage emphasis
- `KB_SNIPPET_AUTO_APPEND.md` - Append mechanism

---

**Summary**: The format is correct - LLM provides summary, tool provides formatted snippets. Removed unused internal summary generation for clarity.

